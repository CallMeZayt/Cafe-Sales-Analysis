{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dccbd5f",
   "metadata": {},
   "source": [
    "#### Import Data CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94eca75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 8) Index(['Transaction ID', 'Item', 'Quantity', ' Price Per Unit', ' Total Spent',\n",
      "       'Payment Method', 'Location', 'Transaction Date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dirty_cafe_sales.csv')\n",
    "print (df.shape, df.columns)\n",
    "# print(df.head(3))\n",
    "# print(df.tail(3))\n",
    "# print(df.describe())\n",
    "\n",
    "# print (df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9639cbed",
   "metadata": {},
   "source": [
    "#### Mengganti nama kolom agar konsisten snake_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8780a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transaction_id', 'item', 'quantity', 'price_per_unit', 'total_spent', 'payment_method', 'location', 'transaction_date']\n"
     ]
    }
   ],
   "source": [
    "df.columns = (\n",
    "    df.columns.str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(' ', '_')\n",
    "    )  # Remove leading/trailing whitespace from column names\n",
    "print(df.columns.tolist())# Display the cleaned column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f11446",
   "metadata": {},
   "source": [
    "#### Mencari data duplikat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f22f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data duplicate = 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Data duplicate =', df.duplicated().sum(), '\\n')  # Display the number of duplicate rows\n",
    "df = df.drop_duplicates()  # Remove duplicate rows if any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54648340",
   "metadata": {},
   "source": [
    "#### Memperbaiki baris data yang missing value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fabefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kolom yang memiliki value null \n",
      "\n",
      "transaction_id         0\n",
      "item                 333\n",
      "quantity             138\n",
      "price_per_unit       179\n",
      "total_spent          173\n",
      "payment_method      2579\n",
      "location            3265\n",
      "transaction_date     159\n",
      "dtype: int64 \n",
      "\n",
      "Data sebelum menghapus baris yang memiliki missing value = (10000, 8) \n",
      "\n",
      "Data setelah menghapus baris yang memiliki missing value = (4550, 8) \n",
      "\n",
      "transaction_id      0\n",
      "item                0\n",
      "quantity            0\n",
      "price_per_unit      0\n",
      "total_spent         0\n",
      "payment_method      0\n",
      "location            0\n",
      "transaction_date    0\n",
      "dtype: int64 \n",
      "\n",
      "   transaction_id      item quantity price_per_unit total_spent  \\\n",
      "0     TXN_1961373    Coffee        2            2.0         4.0   \n",
      "1     TXN_4977031      Cake        4            3.0        12.0   \n",
      "2     TXN_4271903    Cookie        4            1.0       ERROR   \n",
      "3     TXN_7034554     Salad        2            5.0        10.0   \n",
      "4     TXN_3160411    Coffee        2            2.0         4.0   \n",
      "6     TXN_4433211   UNKNOWN        3            3.0         9.0   \n",
      "7     TXN_6699534  Sandwich        4            4.0        16.0   \n",
      "10    TXN_2548360     Salad        5            5.0        25.0   \n",
      "11    TXN_3051279  Sandwich        2            4.0         8.0   \n",
      "12    TXN_7619095  Sandwich        2            4.0         8.0   \n",
      "15    TXN_2847255     Salad        3            5.0        15.0   \n",
      "17    TXN_6769710     Juice        2            3.0         6.0   \n",
      "18    TXN_8876618      Cake        5            3.0        15.0   \n",
      "19    TXN_3709394     Juice        4            3.0        12.0   \n",
      "20    TXN_3522028  Smoothie    ERROR            4.0        20.0   \n",
      "\n",
      "    payment_method  location transaction_date  \n",
      "0      Credit Card  Takeaway       2023-09-08  \n",
      "1             Cash  In-store       2023-05-16  \n",
      "2      Credit Card  In-store       2023-07-19  \n",
      "3          UNKNOWN   UNKNOWN       2023-04-27  \n",
      "4   Digital Wallet  In-store       2023-06-11  \n",
      "6            ERROR  Takeaway       2023-10-06  \n",
      "7             Cash   UNKNOWN       2023-10-28  \n",
      "10            Cash  Takeaway       2023-11-07  \n",
      "11     Credit Card  Takeaway            ERROR  \n",
      "12            Cash  In-store       2023-05-03  \n",
      "15     Credit Card  In-store       2023-11-15  \n",
      "17            Cash  In-store       2023-02-24  \n",
      "18            Cash     ERROR       2023-03-25  \n",
      "19            Cash  Takeaway       2023-01-15  \n",
      "20            Cash  In-store       2023-04-04  \n"
     ]
    }
   ],
   "source": [
    "print('kolom yang memiliki value null', '\\n')  # Check if any column has null values\n",
    "print(df.isna().sum(), '\\n')  # Display the count of missing values in each column\n",
    "\n",
    "# df['quantity'] = df['quantity'].fillna(0)  # Fill missing values in 'quantity' column with 0\n",
    "# df['payment_method'] = df['payment_method'].fillna('UNKNOWN')  # Fill missing values in 'payment_method' column with 'unknown'\n",
    "# df['location'] = df['location'].fillna('UNKNOWN')  # Fill missing values in 'location' column with 'unknown'\n",
    "# df['price_per_unit'] = df['price_per_unit'].fillna(df['price_per_unit'].mean())  # Fill missing values in 'price_per_unit' column with the mean of that column\n",
    "\n",
    "print('Data sebelum menghapus baris yang memiliki missing value =', df.shape, '\\n')  # Display the shape of the DataFrame before removing rows with missing values\n",
    "df = df.dropna()  # Remove rows with any missing values\n",
    "print('Data setelah menghapus baris yang memiliki missing value =', df.shape, '\\n')  # Display the shape of the DataFrame after removing rows with missing values\n",
    "print(df.isna().sum(), '\\n')  # Display the count of missing values in each column\n",
    "print(df.head(15))  # Display the first 15 rows of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86103d75",
   "metadata": {},
   "source": [
    "#### Memperbaiki data yang tidak sesuai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f93960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   transaction_id      item  quantity  price_per_unit  total_spent  \\\n",
      "0     TXN_1961373    Coffee       2.0             2.0          4.0   \n",
      "1     TXN_4977031      Cake       4.0             3.0         12.0   \n",
      "2     TXN_4271903    Cookie       4.0             1.0          4.0   \n",
      "3     TXN_7034554     Salad       2.0             5.0         10.0   \n",
      "4     TXN_3160411    Coffee       2.0             2.0          4.0   \n",
      "6     TXN_4433211   UNKNOWN       3.0             3.0          9.0   \n",
      "7     TXN_6699534  Sandwich       4.0             4.0         16.0   \n",
      "10    TXN_2548360     Salad       5.0             5.0         25.0   \n",
      "11    TXN_3051279  Sandwich       2.0             4.0          8.0   \n",
      "12    TXN_7619095  Sandwich       2.0             4.0          8.0   \n",
      "15    TXN_2847255     Salad       3.0             5.0         15.0   \n",
      "17    TXN_6769710     Juice       2.0             3.0          6.0   \n",
      "18    TXN_8876618      Cake       5.0             3.0         15.0   \n",
      "19    TXN_3709394     Juice       4.0             3.0         12.0   \n",
      "20    TXN_3522028  Smoothie       5.0             4.0         20.0   \n",
      "21    TXN_3567645  Smoothie       4.0             4.0         16.0   \n",
      "22    TXN_5132361  Sandwich       3.0             4.0         12.0   \n",
      "24    TXN_9400181  Sandwich       5.0             4.0         20.0   \n",
      "26    TXN_5183041    Cookie       5.0             1.0          5.0   \n",
      "27    TXN_5695074     Juice       4.0             3.0         12.0   \n",
      "29    TXN_7640952      Cake       4.0             3.0         12.0   \n",
      "31    TXN_8927252   UNKNOWN       2.0             1.0          2.0   \n",
      "34    TXN_8853997  Smoothie       2.0             4.0          8.0   \n",
      "35    TXN_9130559  Sandwich       1.0             4.0          4.0   \n",
      "37    TXN_1080432     Salad       2.0             5.0         10.0   \n",
      "\n",
      "    payment_method  location transaction_date  \n",
      "0      Credit Card  Takeaway       2023-09-08  \n",
      "1             Cash  In-store       2023-05-16  \n",
      "2      Credit Card  In-store       2023-07-19  \n",
      "3          UNKNOWN   UNKNOWN       2023-04-27  \n",
      "4   Digital Wallet  In-store       2023-06-11  \n",
      "6            ERROR  Takeaway       2023-10-06  \n",
      "7             Cash   UNKNOWN       2023-10-28  \n",
      "10            Cash  Takeaway       2023-11-07  \n",
      "11     Credit Card  Takeaway            ERROR  \n",
      "12            Cash  In-store       2023-05-03  \n",
      "15     Credit Card  In-store       2023-11-15  \n",
      "17            Cash  In-store       2023-02-24  \n",
      "18            Cash     ERROR       2023-03-25  \n",
      "19            Cash  Takeaway       2023-01-15  \n",
      "20            Cash  In-store       2023-04-04  \n",
      "21     Credit Card  Takeaway       2023-03-30  \n",
      "22  Digital Wallet  Takeaway       2023-12-01  \n",
      "24            Cash  In-store       2023-06-03  \n",
      "26     Credit Card  In-store       2023-04-20  \n",
      "27     Credit Card  Takeaway       2023-04-10  \n",
      "29  Digital Wallet  Takeaway            ERROR  \n",
      "31     Credit Card     ERROR       2023-11-06  \n",
      "34  Digital Wallet  Takeaway       2023-10-09  \n",
      "35     Credit Card   UNKNOWN       2023-05-28  \n",
      "37     Credit Card  In-store       2023-04-29  \n"
     ]
    }
   ],
   "source": [
    "df[['quantity', 'total_spent', 'price_per_unit']] = df[['quantity', 'total_spent', 'price_per_unit']].replace(['ERROR','UNKNOWN'], pd.NA)  # Replace 'ERROR' with '0' in specified columns\n",
    "\n",
    "\n",
    "\n",
    "df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce')  # Convert 'quantity' to numeric, coercing errors to NaN\n",
    "df['total_spent'] = pd.to_numeric(df['total_spent'], errors='coerce')  # Convert 'total_spent' to numeric, coercing errors to NaN\n",
    "df['price_per_unit'] = pd.to_numeric(df['price_per_unit'], errors='coerce')  # Convert 'price_per_unit' to numeric, coercing errors to NaN\n",
    "\n",
    "# Isi nilai quantity yang kosong jika total_spent dan price_per_unit tersedia\n",
    "mask_q = df['quantity'].isna() & df['total_spent'].notna() & df['price_per_unit'].notna()\n",
    "df.loc[mask_q, 'quantity'] = df.loc[mask_q, 'total_spent'] / df.loc[mask_q, 'price_per_unit']\n",
    "\n",
    "# Isi nilai price_per_unit yang kosong jika total_spent dan quantity tersedia\n",
    "mask_p = df['price_per_unit'].isna() & df['total_spent'].notna() & df['quantity'].notna()\n",
    "df.loc[mask_p, 'price_per_unit'] = df.loc[mask_p, 'total_spent'] / df.loc[mask_p, 'quantity']\n",
    "\n",
    "# Isi nilai total_spent yang kosong jika quantity dan price_per_unit tersedia\n",
    "mask_t = df['total_spent'].isna() & df['quantity'].notna() & df['price_per_unit'].notna()\n",
    "df.loc[mask_t, 'total_spent'] = df.loc[mask_t, 'quantity'] * df.loc[mask_t, 'price_per_unit']\n",
    "\n",
    "print(df.head(25))  # Display the first 15 rows of the DataFrame after cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a08f77",
   "metadata": {},
   "source": [
    "#### Hapus baris dengan nilai 'Error' dan 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfddd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   transaction_id      item  quantity  price_per_unit  total_spent  \\\n",
      "0     TXN_1961373    Coffee       2.0             2.0          4.0   \n",
      "1     TXN_4977031      Cake       4.0             3.0         12.0   \n",
      "2     TXN_4271903    Cookie       4.0             1.0          4.0   \n",
      "4     TXN_3160411    Coffee       2.0             2.0          4.0   \n",
      "10    TXN_2548360     Salad       5.0             5.0         25.0   \n",
      "12    TXN_7619095  Sandwich       2.0             4.0          8.0   \n",
      "15    TXN_2847255     Salad       3.0             5.0         15.0   \n",
      "17    TXN_6769710     Juice       2.0             3.0          6.0   \n",
      "19    TXN_3709394     Juice       4.0             3.0         12.0   \n",
      "20    TXN_3522028  Smoothie       5.0             4.0         20.0   \n",
      "21    TXN_3567645  Smoothie       4.0             4.0         16.0   \n",
      "22    TXN_5132361  Sandwich       3.0             4.0         12.0   \n",
      "24    TXN_9400181  Sandwich       5.0             4.0         20.0   \n",
      "26    TXN_5183041    Cookie       5.0             1.0          5.0   \n",
      "27    TXN_5695074     Juice       4.0             3.0         12.0   \n",
      "\n",
      "    payment_method  location transaction_date  \n",
      "0      Credit Card  Takeaway       2023-09-08  \n",
      "1             Cash  In-store       2023-05-16  \n",
      "2      Credit Card  In-store       2023-07-19  \n",
      "4   Digital Wallet  In-store       2023-06-11  \n",
      "10            Cash  Takeaway       2023-11-07  \n",
      "12            Cash  In-store       2023-05-03  \n",
      "15     Credit Card  In-store       2023-11-15  \n",
      "17            Cash  In-store       2023-02-24  \n",
      "19            Cash  Takeaway       2023-01-15  \n",
      "20            Cash  In-store       2023-04-04  \n",
      "21     Credit Card  Takeaway       2023-03-30  \n",
      "22  Digital Wallet  Takeaway       2023-12-01  \n",
      "24            Cash  In-store       2023-06-03  \n",
      "26     Credit Card  In-store       2023-04-20  \n",
      "27     Credit Card  Takeaway       2023-04-10  \n"
     ]
    }
   ],
   "source": [
    "# df.drop[df['item'] ['ERROR', 'UNKNOWN'])].reset_index(drop=True)\n",
    "df.drop(df[df['item'].isin(['UNKNOWN', 'ERROR']) ].index, inplace=True)\n",
    "df.drop(df[df['location'].isin(['UNKNOWN', 'ERROR']) ].index, inplace=True)\n",
    "df.drop(df[df['payment_method'].isin(['UNKNOWN', 'ERROR']) ].index, inplace=True)\n",
    "df.drop(df[df['transaction_date'].isin(['UNKNOWN', 'ERROR']) ].index, inplace=True)\n",
    "\n",
    "print(df.head(15))  # Display the first 15 rows of the DataFrame after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3180af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dengan price_per_unit kosong sebelum diisi:\n",
      "     transaction_id      item  quantity  price_per_unit  total_spent  \\\n",
      "1216    TXN_2857444  Smoothie       1.0             NaN          NaN   \n",
      "1368    TXN_6424202    Cookie       2.0             NaN          NaN   \n",
      "2499    TXN_5118799    Cookie       2.0             NaN          NaN   \n",
      "2508    TXN_2253622  Sandwich       5.0             NaN          NaN   \n",
      "2796    TXN_6105807  Smoothie       3.0             NaN          NaN   \n",
      "2928    TXN_1525583  Sandwich       3.0             NaN          NaN   \n",
      "2992    TXN_7764304      Cake       NaN             NaN          3.0   \n",
      "\n",
      "      payment_method  location transaction_date  \n",
      "1216            Cash  Takeaway       2023-05-10  \n",
      "1368     Credit Card  In-store       2023-11-20  \n",
      "2499            Cash  Takeaway       2023-04-23  \n",
      "2508  Digital Wallet  Takeaway       2023-09-30  \n",
      "2796     Credit Card  Takeaway       2023-01-18  \n",
      "2928            Cash  Takeaway       2023-05-20  \n",
      "2992     Credit Card  Takeaway       2023-01-09  \n",
      "\n",
      "Data setelah price_per_unit diisi:\n",
      "  transaction_id      item  quantity  price_per_unit  total_spent  \\\n",
      "0    TXN_1961373    Coffee       2.0             2.0          4.0   \n",
      "1    TXN_4977031      Cake       4.0             3.0         12.0   \n",
      "2    TXN_4271903    Cookie       4.0             1.0          4.0   \n",
      "3    TXN_3160411    Coffee       2.0             2.0          4.0   \n",
      "4    TXN_2548360     Salad       5.0             5.0         25.0   \n",
      "5    TXN_7619095  Sandwich       2.0             4.0          8.0   \n",
      "6    TXN_2847255     Salad       3.0             5.0         15.0   \n",
      "7    TXN_6769710     Juice       2.0             3.0          6.0   \n",
      "8    TXN_3709394     Juice       4.0             3.0         12.0   \n",
      "9    TXN_3522028  Smoothie       5.0             4.0         20.0   \n",
      "\n",
      "   payment_method  location transaction_date  \n",
      "0     Credit Card  Takeaway       2023-09-08  \n",
      "1            Cash  In-store       2023-05-16  \n",
      "2     Credit Card  In-store       2023-07-19  \n",
      "3  Digital Wallet  In-store       2023-06-11  \n",
      "4            Cash  Takeaway       2023-11-07  \n",
      "5            Cash  In-store       2023-05-03  \n",
      "6     Credit Card  In-store       2023-11-15  \n",
      "7            Cash  In-store       2023-02-24  \n",
      "8            Cash  Takeaway       2023-01-15  \n",
      "9            Cash  In-store       2023-04-04  \n"
     ]
    }
   ],
   "source": [
    "# Load data csv\n",
    "df = pd.read_csv('cleaned_data_fix.csv')\n",
    "\n",
    "# Definisikan harga per item sesuai kebutuhan\n",
    "price_dict = {\n",
    "    'Coffee': 2,\n",
    "    'Cake': 3,\n",
    "    'Cookie': 1,\n",
    "    'Salad': 5,\n",
    "    'Sandwich': 4,\n",
    "    'Juice': 3,\n",
    "    'Smoothie': 4,\n",
    "    'Tea': 1.5\n",
    "}\n",
    "\n",
    "# Cek nilai kosong pada price_per_unit sebelum diisi\n",
    "print(\"Data dengan price_per_unit kosong sebelum diisi:\")\n",
    "print(df[df['price_per_unit'].isnull()])\n",
    "\n",
    "# Hapus baris yang quantity dan total_spent kosong (NaN)\n",
    "df = df.dropna(subset=['quantity', 'total_spent'], how='all')\n",
    "\n",
    "# Isi nilai price_per_unit yang kosong berdasarkan nama item\n",
    "df['price_per_unit'] = df.apply(\n",
    "    lambda row: price_dict[row['item']] if pd.isna(row['price_per_unit']) else row['price_per_unit'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Hitung total_spent = quantity * price_per_unit untuk semua baris\n",
    "df['total_spent'] = df['quantity'] * df['price_per_unit']\n",
    "\n",
    "# Cek hasil pengisian\n",
    "print(\"\\nData setelah price_per_unit diisi:\")\n",
    "print(df[df['price_per_unit'].isnull() == False].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b95f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transaction_date'] = pd.to_datetime(df['transaction_date'])  # Convert 'transaction_date' to datetime format, coercing errors to NaT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fd00d",
   "metadata": {},
   "source": [
    "#### Simpan DataFrame hasil cleaning ke file CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f2aad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File dengan kolom price_per_unit yang diisi sudah disimpan: 'cleaned_data_price_filled.csv'\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('cleaned_data_price_filled.csv', index=False)\n",
    "print(\"\\nFile dengan kolom price_per_unit yang diisi sudah disimpan: 'cleaned_data_price_filled.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
